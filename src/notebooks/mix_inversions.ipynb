{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mix of Inversion files\n",
    "\n",
    "The aim of this notebook is to mix indoor and outdoor inversion data to create a full synthetic dataset.\n",
    "\n",
    "Size fo indoor and outdoor datasets are as following:\n",
    "\n",
    "- indoor images are 229, with 0° and 180° phase which leads to 458 inverted holeographic images.\n",
    "- outdoor images are 208, with 0° and 180° phase which leads to 416 inverted holeographic images.\n",
    "\n",
    "Our goal here is to mix all these possible combination of images.\n",
    "\n",
    "The parameters that we take into consideration to mix that dataset (and that will remain as metadata file) are:\n",
    "\n",
    "- indoor\n",
    "  - object number (0 - 14)\n",
    "  - orientation (A, B, C, D)\n",
    "  - distance from source (4, 8)\n",
    "  - inclination (0, 20)\n",
    "- outdoor\n",
    "  - orientation (A, B, C, D)\n",
    "\n",
    "Regarding the inversion, we also have an additional parameter for both indoor and outdoor:\n",
    "\n",
    "- indoor\n",
    "  - inversion phase (0, 180)\n",
    "- outdoor\n",
    "  - inversion phase (0, 180)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indoor and Outdoor metadata\n",
    "\n",
    "The idea is to have `indoor` and `outdoor` metadata as `CSV` files.\n",
    "\n",
    "These files will eventually be used for mixing information.\n",
    "\n",
    "```\n",
    "  ├── interim/               - inversion folder\n",
    "  │   ├── indoor/               - indoor inversion\n",
    "  │   │    ├── 1-A-4-20-0.npy\n",
    "  │   │    ├── 1-A-4-20-180.npy\n",
    "  │   │    └── ...\n",
    "  │   └── outdoor/              - outdoor inversion\n",
    "  │        ├── 1-25-4-0.npy\n",
    "  │        ├── 1-25-4-180.npy\n",
    "  │        └──...\n",
    "  │\n",
    "  ├── processed/\n",
    "  │   └── meta/                 - outdoor inversion\n",
    "  │        ├── indoor.csv           - annotation for indoor dataset\n",
    "  │        ├── outdoor.csv          - annotation for outdoor dataset\n",
    "  │        └── mixed.csv            - annotation for mixed dataset (indoor and outdoor) all possible combinations\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset structure\n",
    "\n",
    "The main forlder will be `processed`.\n",
    "\n",
    "Then, while the `abcdefg.npy` object is obviously a `numpy` tensor of `[62, 62, 40]` shape (or `[40, 62, 62]`), the json metadata file is organized as follow:\n",
    "\n",
    "---\n",
    "\n",
    "```csv\n",
    "file_name, id, location, category, name, orientation, distance_from_source, inclination, inversion_phase, shape\n",
    "in_low_01_20_A_6_180, 01, \"indoor\", \"mine\", \"pmn-4\", \"A\", 8, 20, 180, \"zig-zag\"\n",
    "in_low_01_20_A_6_0, 01, \"indoor\", \"mine\", \"pmn-4\", \"A\", 8, 20, 0, \"zig-zag\"\n",
    "...\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "```csv\n",
    "file_name, id, location, category, orientation, inversion_phase, shape, additional\n",
    "43_25_6_180, 43, \"outdoor\", \"ground-smarta\", 25, 180, \"zig-zag\", null\n",
    "43_25_6_0, 43, \"outdoor\", \"ground-smarta\", 25, 0, \"zig-zag\", null\n",
    "...\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "And then we also have mixed inversions as follow:\n",
    "\n",
    "---\n",
    "\n",
    "```csv\n",
    "mix_name, in_name, in_id, in_category, in_orientation, in_distance_from_source, in_inclination, in_inversion_phase, in_shape, out_name, out_id, out_category, out_orientation, out_inversion_phase, out_shape, out_additional\n",
    "\n",
    "in_low_01_20_A_6_180-43_25_6_180, in_low_01_20_A_6_180, 01, \"pmn-4\", \"A\", 8, 20, 180, \"zig-zag\", 43_25_6_180, 43, \"ground-smarta\", 25, 180, \"zig-zag\", null\n",
    "in_low_01_20_A_6_0-43_25_6_0, in_low_01_20_A_6_0, 01, \"pmn-4\", \"A\", 8, 20, 0, \"zig-zag\", 43_25_6_0, 43, \"ground-smarta\", 25, 0, \"zig-zag\", null\n",
    "...\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from src.utils.const import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "locations = ['indoor', 'outdoor']\n",
    "prefixes = {\n",
    "    'indoor': ['in'],\n",
    "    'outdoor': ['']\n",
    "}\n",
    "positions = {\n",
    "    'indoor': ['bas', 'low', 'pad'],\n",
    "    'outdoor': ['']\n",
    "}\n",
    "\n",
    "in_categories = []\n",
    "\n",
    "\n",
    "df = pd.read_csv(datapath / Path('raw/indoor_objects.csv'))\n",
    "interimpath = datapath / Path('interim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/emanuelevivoli/asmara/data/processed/meta')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {k: (v1, v2) for k, (v1, v2) in zip(\n",
    "    df['id'], zip(df['name'], df['classification']))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ('pmn4', 'mine'),\n",
       " 2: ('pmn1', 'mine'),\n",
       " 3: ('vs50', 'mine'),\n",
       " 4: ('dm11', 'mine'),\n",
       " 5: ('M14', 'mine'),\n",
       " 6: ('pma2', 'mine'),\n",
       " 7: ('wood-cylinder', 'clutter'),\n",
       " 8: ('wrapped-can', 'clutter'),\n",
       " 9: ('stone', 'clutter'),\n",
       " 10: ('coin', 'archeology'),\n",
       " 11: ('clay-holes', 'archeology'),\n",
       " 12: ('clay-full', 'archeology'),\n",
       " 13: ('clay-big', 'archeology'),\n",
       " 14: ('knife', 'archeology')}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indoor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = list(range(0, 6))\n",
    "# name, id, category, orientation, distance_from_source, inclination, inversion_phase, shape\n",
    "prefix = 'in'\n",
    "keys = [\"location\", \"distance_from_source\", \"id\", \"orientation\",\n",
    "        \"shape\", \"inversion_phase\"]  # inclination, name, category\n",
    "\n",
    "############\n",
    "#! INDOOR\n",
    "############\n",
    "\n",
    "location = 'indoor'\n",
    "in_metadata = []\n",
    "# in_inversions = []\n",
    "\n",
    "names = os.listdir(os.path.join(interimpath, location))\n",
    "names = [name for name in names if name.endswith('.npy')]\n",
    "\n",
    "for name in names:\n",
    "\n",
    "    name = name.split('.')[0]\n",
    "    name_list = name.split('_')\n",
    "    if len(name_list) > 6:\n",
    "        custom_indexes = np.ones(len(indexes), dtype=int)\n",
    "        custom_indexes[0] = 0\n",
    "        custom_indexes[1] = 0\n",
    "        custom_indexes[2] = 0\n",
    "        custom_indexes += indexes\n",
    "        inclination = 20\n",
    "    else:\n",
    "        inclination = 0\n",
    "        custom_indexes = indexes\n",
    "\n",
    "    obj = {}\n",
    "    for c_index, c_key in zip(custom_indexes, keys):\n",
    "        obj[f'{prefix}_{c_key}'] = name_list[c_index]\n",
    "\n",
    "    # obj['location'] = 'indoor' if obj['location'] == 'in' else 'outdoor'\n",
    "    obj[f'{prefix}_location'] = location\n",
    "    obj[f'{prefix}_distance_from_source'] = 8 if obj[f'{prefix}_distance_from_source'] == 'low' else 4 if obj[f'{prefix}_distance_from_source'] == 'bas' else None\n",
    "    obj[f'{prefix}_inclination'] = inclination\n",
    "    obj[f'{prefix}_file_name'] = name\n",
    "    category_, name_ = df_dict.get(int(obj[f'{prefix}_id']), (None, None))\n",
    "    # category = \"mine\"\n",
    "    obj[f'{prefix}_category'] = category_\n",
    "    # name = \"pmn-4\"\n",
    "    obj[f'{prefix}_name'] = name_\n",
    "\n",
    "    in_metadata.append(obj)\n",
    "\n",
    "    # inv_file = np.load(os.path.join(interimpath, location, f'{name}.npy'))\n",
    "    # in_inversions.append(inv_file)\n",
    "\n",
    "# assert len(in_inversions) == len(in_metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_df = pd.DataFrame.from_dict(in_metadata)\n",
    "in_columns = ['file_name', 'id', 'category', 'name', 'orientation', 'distance_from_source', 'inclination', 'inversion_phase', 'shape', 'location']\n",
    "in_columns = [f'{prefix}_{column}' for column in in_columns]\n",
    "in_df.to_csv(metapath / Path('indoor.csv'), index=False, header=True,\n",
    "             columns=in_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outdoor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = list(range(0, 4))\n",
    "prefix = 'out'\n",
    "keys = [\"id\", \"orientation\", \"shape\", \"inversion_phase\"]\n",
    "\n",
    "############\n",
    "#! OUTDOOR\n",
    "############\n",
    "\n",
    "location = 'outdoor'\n",
    "out_metadata = []\n",
    "out_inversions = []\n",
    "\n",
    "names = os.listdir(os.path.join(interimpath, location))\n",
    "names = [name for name in names if name.endswith('.npy')]\n",
    "\n",
    "for name in names:\n",
    "\n",
    "    name = name.split('.')[0]\n",
    "    name_list = name.split('_')\n",
    "    if len(name_list) > 4:\n",
    "        custom_indexes = np.zeros(len(indexes), dtype=int)\n",
    "        custom_indexes[3] = 1\n",
    "        custom_indexes += indexes\n",
    "        additional = name_list[3]\n",
    "    else:\n",
    "        additional = None\n",
    "        custom_indexes = indexes\n",
    "\n",
    "    obj = {}\n",
    "    for c_index, c_key in zip(custom_indexes, keys):\n",
    "        obj[f'{prefix}_{c_key}'] = name_list[c_index]\n",
    "\n",
    "    obj[f'{prefix}_additional'] = additional\n",
    "    obj[f'{prefix}_file_name'] = name\n",
    "    obj[f'{prefix}_location'] = location\n",
    "\n",
    "    category_ = 'ground-smarta'\n",
    "    # category = \"mine\"\n",
    "    obj[f'{prefix}_category'] = category_\n",
    "\n",
    "    out_metadata.append(obj)\n",
    "\n",
    "    # inv_file = np.load(os.path.join(interimpath, location, f'{name}.npy'))\n",
    "    # out_inversions.append(inv_file)\n",
    "\n",
    "# assert len(out_inversions) == len(out_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame.from_dict(out_metadata)\n",
    "out_columns=['file_name', 'id', 'category', 'orientation', 'inversion_phase', 'shape', 'location', 'additional']\n",
    "out_columns = [f'{prefix}_{column}' for column in out_columns]\n",
    "out_df.to_csv(metapath / Path('outdoor.csv'), index=False, header=True,\n",
    "              columns=out_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixig In with Out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 458/458 [00:01<00:00, 337.40it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# mix_inversion = []\n",
    "\n",
    "mix_metadata = []\n",
    "\n",
    "if not os.path.exists(metapath):\n",
    "    os.makedirs(metapath)\n",
    "\n",
    "# if not os.path.exists(os.path.join(DATA_PROC, 'inversions')):\n",
    "#     os.makedirs(os.path.join(DATA_PROC, 'inversions'))\n",
    "\n",
    "for i in tqdm(range(len(in_metadata))):\n",
    "    in_meta = in_metadata[i]\n",
    "    # in_inv = in_inversions[i]\n",
    "\n",
    "    for j in range(len(out_metadata)):\n",
    "        out_meta = out_metadata[j]\n",
    "        # out_inv = out_inversions[j]\n",
    "\n",
    "        # indexes\n",
    "        # print(f'{i}/{len(in_inversions)} - {j}/{len(out_inversions)}')\n",
    "\n",
    "        # mixing metadata\n",
    "        meta = {}\n",
    "        meta['mix_name'] = f'{in_meta[\"in_file_name\"]}__out_{out_meta[\"out_file_name\"]}'\n",
    "        # meta['indoor'] = in_meta\n",
    "        # meta['outdoor'] = out_meta\n",
    "        meta = {**meta, **in_meta, **out_meta}\n",
    "        mix_metadata.append(meta)\n",
    "\n",
    "        # with open(f'{metapath}/{meta[\"name\"]}.json', 'w') as f:\n",
    "        #     json.dump(meta, f)\n",
    "\n",
    "        # ? we don't need to create the mixing dataset ...\n",
    "        # ? we actually mix them online :)\n",
    "        # mixing tensors\n",
    "        # mixed_inv = in_inv + out_inv\n",
    "        # mix_inversion.append(mixed_inv)\n",
    "        # np.save(file=f'{DATA_PROC}/inversions/{meta[\"name\"]}.npy', arr=mixed_inv)\n",
    "\n",
    "# assert len(mix_inversion) == len(mix_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_df = pd.DataFrame.from_dict(mix_metadata)\n",
    "\n",
    "mix_columns=['mix_name'] + in_columns + out_columns\n",
    "mix_df.to_csv(metapath / Path('mix.csv'), index=False, header=True,\n",
    "              columns=mix_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mypython3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8148f3366ec21db64bd0484ee2e8d964d27d8e8b73627767738b51624036cdd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
